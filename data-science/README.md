# Data Science â€” SentimentAPI (Twitter Airline)

Este directorio contiene todo el avance de **Data Science**: desde la carga del dataset y limpieza del texto, hasta el entrenamiento del modelo, evaluaciÃ³n y exportaciÃ³n de artefactos para producciÃ³n (FastAPI).

> Objetivo: clasificar textos como **positivo (1)** vs **negativo (0)** y exponer el modelo mediante una API para que el backend lo consuma.

---

## âœ… Resultado esperado

Al finalizar, deberÃ­as tener:

1. Un notebook reproducible end-to-end:
   - EDA â†’ limpieza â†’ split â†’ entrenamiento â†’ evaluaciÃ³n â†’ exportaciÃ³n
2. Un modelo baseline funcional:
   - **TF-IDF + Logistic Regression** (scikit-learn)
3. MÃ©tricas y validaciones:
   - Accuracy / Precision / Recall / F1-score
   - Matriz de confusiÃ³n
   - Sanity check anti-leakage (label shuffle)
4. Artefactos exportados para producciÃ³n:
   - `sentiment_pipeline_balanced.joblib`
   - `threshold.txt`
   - `model_config.json`
5. Microservicio **FastAPI** listo para inferencia:
   - `/health`
   - `/predict`

---

## ðŸ“ Estructura del directorio

- data-science/
  * README.md
  * Customer_Sentiment.csv
  * Customer_Sentiment_final.csv
  * Customer_Sentiment_final2.csv
  * Sentiment_Final.ipynb

- artifacts/
  * sentiment_pipeline_balanced.joblib
  * threshold.txt
  * model_config.json

- service/
  * main.py
  * requirements.txt


---

## ðŸ”Ž Conceptos clave (explicado simple)

### 1) Â¿QuÃ© es `texto_de_review` vs `texto_clean`?
- **`texto_de_review`**: texto crudo original (como viene en Twitter).
- **`texto_clean`**: texto normalizado para modelado (minÃºsculas, sin URLs, sin menciones, etc.).

âœ… El modelo se entrena y predice usando **`texto_clean`**.

---

### 2) Â¿QuÃ© es `joblib` y por quÃ© existe `sentiment_pipeline_balanced.joblib`?
`joblib` es una herramienta para **guardar y cargar objetos de Python** (serializaciÃ³n).

El archivo:
- `sentiment_pipeline_balanced.joblib`

contiene el **pipeline completo** ya entrenado:
- TF-IDF (vectorizador)
- Logistic Regression (clasificador)

âœ… Esto permite usar el modelo en producciÃ³n sin re-entrenar.

---

### 3) Â¿QuÃ© es el `threshold` (umbral) y por quÃ© existe `threshold.txt`?
El modelo entrega probabilidades (ej. 0.73 = 73% de ser positivo).
Para convertir eso en 0/1, usamos un umbral:

- si `probabilidad >= threshold` â†’ **positivo (1)**
- si `probabilidad < threshold` â†’ **negativo (0)**

En este proyecto se eligiÃ³:
- `threshold = 0.40`

porque mejora el **recall de positivos** (detecta mÃ¡s positivos reales), a costa de mÃ¡s falsos positivos.

âœ… Guardamos el valor en `threshold.txt` para que FastAPI y backend usen el mismo criterio.

---

### 4) Â¿QuÃ© es `model_config.json`?
Es un archivo de configuraciÃ³n/documentaciÃ³n del modelo (metadatos), por ejemplo:
- threshold elegido
- polÃ­tica de labels (positive=1, neutral/negative=0)
- configuraciÃ³n del pipeline (ngram_range, max_features, etc.)

âœ… No es el modelo. Es un â€œmanualâ€ reproducible de cÃ³mo se construyÃ³.

---

### 5) Â¿QuÃ© es `main.py` y `requirements.txt`?
- **`main.py`**: el microservicio FastAPI que carga el modelo y expone endpoints.
- **`requirements.txt`**: lista de dependencias para instalar el entorno:
  - fastapi, uvicorn, scikit-learn, joblib

âœ… Esto permite ejecutar el servicio igual en cualquier PC.

---

### 6) Â¿Que es Customer_sentiment...?
- Primera version del proyecto; un intento de sentiment el cual ayudo a plasmar el camino y aprender lo basico.
- Si bien resulto ser poco practico, sirvio para profundizar en la via a seguir y ser una buena prueba

âœ… A pesar de los contratiempos, hubo aprendizaje valioso.

---

## ðŸ§ª Notebook (Colab) â€” CÃ³mo correrlo

### Requisitos
- Google Colab o Jupyter Notebook con Python 3.10+.
- Acceso al dataset (HuggingFace datasets vÃ­a `hf://...`).

### Pasos recomendados
1. Abrir `Sentiment_Final.ipynb`
2. Ejecutar:
   - **Runtime â†’ Restart and run all**
3. Verificar que al final se generen los artefactos exportados:
   - `sentiment_pipeline_balanced.joblib`
   - `threshold.txt`
   - `model_config.json`

---

## ðŸ“¦ ExportaciÃ³n de artefactos (desde Colab)

Al final del notebook se exportan archivos. Para descargarlos en Colab:

```python
from google.colab import files

files.download("sentiment_pipeline_balanced.joblib")
files.download("threshold.txt")
files.download("model_config.json")
